{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing Patronage on YouTube\n",
    "\n",
    "## 0. Files and brief explanation of those\n",
    "\n",
    "All data is located in `/dlabdata1/youtube_large/`\n",
    "\n",
    "**YouNiverse dataset:**\n",
    "\n",
    "- `df_channels_en.tsv.gz`: channel metadata.\n",
    "- `df_timeseries_en.tsv.gz`: channel-level time-series.\n",
    "- `yt_metadata_en.jsonl.gz`: raw video metadata.\n",
    "- `youtube_comments.tsv.gz`: user-comment matrices.\n",
    "- `youtube_comments.ndjson.zst`: raw comments — this is a HUGE file.\n",
    "\n",
    "**Graphteon dataset:**\n",
    "- `creators.csv` list with all creator names.\n",
    "- `final_processed_file.jsonl.gz` all graphteon time-series.\n",
    "- `pages.zip` raw html of the pages in graphteon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "import zstandard\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/dlabdata1/youtube_large/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all files in DATA_FOLDER\n",
    "# !ls -lh /dlabdata1/youtube_large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. YouNiverse dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Channel metadata\n",
    "Metadata associated with the 136,470 channels: **channel ID**, **join date**, **country**, **number of subscribers**, **most frequent category**, and the **channel’s position** in socialblade.com’s subscriber ranking. \\\n",
    "The number of subscribers is provided both as obtained from channelcrawler.com (between 2019-09-12 and 2019-09-17) and as crawled from socialblade.com (2019-09-27). Additionally, we also provide a set of **weights** (derived from socialblade.com’s subscriber rankings) that can be used to partially correct sample biases in our dataset.\n",
    "\n",
    "- `category_cc`: most frequent category ??\n",
    "- `join_date`\n",
    "- `channel`\n",
    "- `name_cc`\n",
    "- `subscribers_cc`: number of subscribers\n",
    "- `videos_cc`\n",
    "- `subscriber_rank_sb`: channel’s position in socialblade.com’s subscriber ranking\n",
    "- `weights`: Set of derived from socialblade.com’s subscriber rankings. Can be used to partially correct sample biases in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh /dlabdata1/youtube_large/df_channels_en.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel metadata\n",
    "df_yt_channels = pd.read_csv(DATA_FOLDER+'df_channels_en.tsv.gz', sep=\"\\t\", compression='gzip')\n",
    "df_yt_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1.1 Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique categories:         {:,}'.format(df_yt_channels['category_cc'].nunique()))\n",
    "print('Number of unique channels:      {:,}'.format(df_yt_channels['channel'].nunique()))\n",
    "print('Number of unique channel names: {:,}'.format(df_yt_channels['name_cc'].nunique()))\n",
    "\n",
    "print('\\nNote: there are more unique channels than unique names, so some channels might have the same name!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1.2 Distribution of videos and subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['videos_cc', 'subscribers_cc']\n",
    "\n",
    "# plot with linear scale for x axis \n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "for i,(col,ax) in enumerate(zip(selected_cols, axs.flatten())):\n",
    "    sns.histplot(data=df_yt_channels[col], ax=ax, bins=50, kde=False, color=f'C{i}')\n",
    "    ax.set(title=f'Distribution of {col}')\n",
    "    ax.set_ylabel(\"Count - number of channels\")\n",
    "    ax.set(yscale=\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot with log scale for x axis \n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "for i,(col,ax) in enumerate(zip(selected_cols, axs.flatten())):\n",
    "    sns.histplot(data=df_yt_channels[col], ax=ax, bins=2000, kde=False, color=f'C{i}')\n",
    "\n",
    "    ax.set(title=f'Distribution of {col} (log-log scale)')\n",
    "    ax.set_ylabel(\"Count - number of channels\")\n",
    "    ax.set(yscale=\"log\")\n",
    "    ax.set(xscale=\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# descriptive statistics table\n",
    "df_yt_channels[selected_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** \\\n",
    "From the above graphs and table, we can see that _videos_ and _subscribers_ distributions among YouTube channels follow a **power law**, meaning that most channels have a only a few videos and a few subscribers, but a few of them have a lot of videos and a lot of subscribers.\n",
    "\n",
    "More specifically:\n",
    "- 50% of the YouTube channels have less than 175 videos\n",
    "- 50% of the YouTube channels have less than 42,400 subscribers videos\n",
    "\n",
    "_Note: only channels with at least 10 videos and 10,000 subscribers were considered for this study._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1.2 Channel time-series\n",
    "(Weekly number of viewers and subscribers)\n",
    "\n",
    "Time series of channel activity at **weekly granularity**. The span of time series varies by channel depending on when socialblade.com started tracking the channel. On average, it contains **2.8 years of data per channel** for **133k channels** (notice that this means there are roughly 4k channels for which there is no time-series data). \\\n",
    "Each data point includes the **number of views** (`views`) and **subscribers** (`subs`) obtained in the given week, as well as the **number of videos** (`videos`) posted by the **channel** (`channel`). The number of videos is calculated using the video upload dates in our video metadata, such that videos that were unavailable at crawl time are not accounted for. \n",
    "\n",
    "---\n",
    "\n",
    "Time series related to each channel.\\\n",
    "These come from a mix of YouTube data and time series crawled from [socialblade.com](https://socialblade.com/):\n",
    "- From the former (YouTube data): derived weekly time series indicating **how many videos each channel had posted per week**. \n",
    "- From the latter (socialblade.com): crawled weekly statistics on the **number of viewers** `views` and **subscribers** `subs` per channel `channel`. This data was available for around 153k channels.\n",
    "\n",
    "    - `channel`: unique channel ID, which is the numbers and letters at the end of the URL.\n",
    "    - `category`: Content categories organize channels and videos on YouTube and help creators, advertisers, and channel managers identify with content and audiences they wish to associate with.\n",
    "    - `datetime`: date of first day of the week?\n",
    "    - `views`: number of views obtained in the given week\n",
    "    - `delta_views`: difference of number of views between current and former week \n",
    "    - `subs`: number of subscribers per channel\n",
    "    - `delta_subs`: difference of number of subscribers between current and former week\n",
    "    - `videos`: number of videos posted by the channel up to date\n",
    "    - `delta_videos`: difference of number of videos posted by the channel between current and former week\n",
    "    - `activity`: ???\n",
    "    \n",
    "    \n",
    "Note: Can view the channel by appending the channel id to the url, e.g.  https://www.youtube.com/channel/UCBJuEqXfXTdcPSbGO9qqn1g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh /dlabdata1/youtube_large/df_timeseries_en.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel-level time-series.\n",
    "df_yt_timeseries = pd.read_csv(DATA_FOLDER+'df_timeseries_en.tsv.gz', sep=\"\\t\", compression='gzip', parse_dates=['datetime'])\n",
    "df_yt_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2.1 Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yt_timeseries.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Timeseries data was gathered between {} and {}'.format(df_yt_timeseries['datetime'].min().strftime('%B %d, %Y'),\n",
    "                                                         df_yt_timeseries['datetime'].max().strftime('%B %d, %Y')))\n",
    "print('Total number of datapoints accross all channels: {:>12,}'.format(len(df_yt_timeseries)))\n",
    "data_points_dist = df_yt_timeseries['channel'].value_counts()\n",
    "print('Average number of datapoints per channel:       {:>12.0f} weeks (≈{:,.1f} years)'.format(data_points_dist.mean(), data_points_dist.mean()/52))\n",
    "print('Number of unique categories:                     {:>12,}'.format(df_yt_timeseries['category'].nunique()))\n",
    "print('Number of unique channels:                       {:>12,}'.format(df_yt_timeseries['channel'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ditribution of datapoints per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_ts_year_cnt = df_yt_timeseries.groupby(df_yt_timeseries.datetime.dt.year).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Timeseries data was gathered between {} and {}'.format(df_yt_timeseries['datetime'].min().strftime('%B %d, %Y'),\n",
    "                                                         df_yt_timeseries['datetime'].max().strftime('%B %d, %Y')))\n",
    "yt_ts_year_cnt.plot(kind='bar')\n",
    "plt.title(\"Nb of datapoints per year accross all channels\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count (datapoints)\")\n",
    "plt.show()\n",
    "\n",
    "data_per_cat['subscribers_cc_sum'].sort_values(ascending=False)\n",
    "\n",
    "yt_ts_year_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ditribution of datapoints per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_ts_month_cnt = df_yt_timeseries_merged.groupby([df_yt_timeseries_merged.datetime.dt.year, df_yt_timeseries_merged.datetime.dt.month]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of datapoints per month\n",
    "plt.figure(figsize=(15,6))\n",
    "yt_ts_month_cnt.plot(kind='bar')\n",
    "plt.title(\"Number of datapoints per month accross all channels\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count (datapoints)\")\n",
    "plt.show()\n",
    "\n",
    "yt_ts_month_cnt.head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of datapoints accross channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of datapoints accross channels\n",
    "\n",
    "print('Total number of datapoints accross all channels: {:>12,}'.format(len(df_yt_timeseries)))\n",
    "data_points_dist = df_yt_timeseries['channel'].value_counts()\n",
    "print('Average number of datapoints per channel:        {:>12,.0f} weeks (≈{:,.1f} years)'.format(data_points_dist.mean(), data_points_dist.mean()/52))\n",
    "\n",
    "ax = sns.histplot(data=data_points_dist, bins=50, kde=False, color=f'C{1}')\n",
    "\n",
    "ax.set(title=f'Distribution of datapoints (weeks) accross channels')\n",
    "ax.set_xlabel('number of data points (weeks)')\n",
    "ax.set_ylabel('number of channels')\n",
    "\n",
    "# ax.set(yscale=\"log\")\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_cols = ['datetime', 'views', 'delta_views', 'subs', 'delta_subs', 'videos', 'delta_videos', 'activity']\n",
    "data_per_channel = df_yt_timeseries.groupby('channel')[sel_cols].agg(['min', 'max', 'count', 'mean'])\n",
    "data_per_channel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  1.1.2.2 Views per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_channel['views'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of total views per channel\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\n",
    "\n",
    "# print(axs[0])\n",
    "sns.histplot(data=data_per_channel['views']['max'], ax=axs[0], bins=20, kde=False, color=f'C{1}')\n",
    "\n",
    "axs[0].set(title=f'Distribution of total views per channel')\n",
    "axs[0].set_xlabel('number of views (in billions)')\n",
    "axs[0].set_ylabel('number of channels')\n",
    "\n",
    "axs[0].set(yscale=\"log\")\n",
    "\n",
    "xlabels1 = ['{:,.0f}'.format(x) + 'bn' for x in axs[0].get_xticks()/1_000_000_000]\n",
    "axs[0].set_xticklabels(xlabels1)\n",
    "\n",
    "\n",
    "# # Distribution of total views per channel (log scale)\n",
    "sns.histplot(data=data_per_channel['views']['max'], ax=axs[1], bins=1000, kde=False, color=f'C{1}')\n",
    "\n",
    "axs[1].set(title=f'Distribution of total views per channel (log-log scale)')\n",
    "axs[1].set_xlabel('number of views (in millions)')\n",
    "axs[1].set_ylabel('number of channels')\n",
    "\n",
    "axs[1].set(yscale=\"log\")\n",
    "axs[1].set(xscale=\"log\")\n",
    "\n",
    "# plt.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "xlabels2 = ['{:,.0f}'.format(x) + 'M' for x in axs[1].get_xticks()/1_000_000]\n",
    "axs[1].set_xticklabels(xlabels2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "data_per_channel['views'][['max']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 channels with the most total views (in billions):\")\n",
    "\n",
    "for index, value in data_per_channel['views']['max'].sort_values(ascending=False)[:10].items():\n",
    "    print('https://www.youtube.com/channel/{} : {:,.1f} bn views'.format(index, value/1_000_000_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2.3. Videos per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_channel['videos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of total videos per channel\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\n",
    "sns.histplot(data=data_per_channel['videos']['max'], ax=axs[0], bins=20, kde=False, color=f'C{1}')\n",
    "\n",
    "axs[0].set(title=f'Distribution of total videos per channel')\n",
    "axs[0].set_xlabel('number of videos')\n",
    "axs[0].set_ylabel('number of channels')\n",
    "axs[0].set(yscale=\"log\")\n",
    "\n",
    "# # Distribution of total views per channel (log scale)\n",
    "sns.histplot(data=data_per_channel['videos']['max'], ax=axs[1], bins=100, kde=False, color=f'C{1}')\n",
    "\n",
    "axs[1].set(title=f'Distribution of total videos per channel (log-log scale)')\n",
    "axs[1].set_xlabel('number of videos')\n",
    "axs[1].set_ylabel('number of channels')\n",
    "axs[1].set(yscale=\"log\")\n",
    "axs[1].set(xscale=\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "data_per_channel['videos'][['max']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 channels with the most total videos:\")\n",
    "\n",
    "for index, value in data_per_channel['videos']['max'].sort_values(ascending=False)[:10].items():\n",
    "    print('https://www.youtube.com/channel/{} : {:,.0f} videos'.format(index, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2.4. Subscribers per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_channel['subs'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of total videos per channel\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\n",
    "sns.histplot(data=data_per_channel['subs']['max'], ax=axs[0], bins=20, kde=False, color=f'C{1}')\n",
    "\n",
    "axs[0].set(title=f'Distribution of total subscribers per channel')\n",
    "axs[0].set_xlabel('number of subscribers (in millions)')\n",
    "axs[0].set_ylabel('number of channels')\n",
    "axs[0].set(yscale=\"log\")\n",
    "xlabels0 = ['{:,.0f}'.format(x) + 'M' for x in axs[0].get_xticks()/1_000_000]\n",
    "axs[0].set_xticklabels(xlabels0)\n",
    "\n",
    "# # Distribution of total views per channel (log scale)\n",
    "sns.histplot(data=data_per_channel['subs']['max'], ax=axs[1], bins=500, kde=False, color=f'C{1}')\n",
    "\n",
    "axs[1].set(title=f'Distribution of total subscribers per channel (log-log scale)')\n",
    "axs[1].set_xlabel('number of subscribers')\n",
    "axs[1].set_ylabel('number of channels')\n",
    "axs[1].set(yscale=\"log\")\n",
    "axs[1].set(xscale=\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "data_per_channel['videos'][['max']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_channel['subs']['max'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 channels with the most total subscribers:\")\n",
    "\n",
    "for index, value in data_per_channel['subs']['max'].sort_values(ascending=False)[:10].items():\n",
    "    print('https://www.youtube.com/channel/{} : {:,.1f}M subscribers'.format(index, value/1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the columns to the top level of the multi-index\n",
    "# data_per_channel.columns = data_per_channel.columns.get_level_values(0)\n",
    "# data_per_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Raw video metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /dlabdata1/youtube_large/yt_metadata_en.jsonl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! zcat /dlabdata1/youtube_large/yt_metadata_en.jsonl.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt_metadata = pd.read_json(DATA_FOLDER+'yt_metadata_en.jsonl.gz', compression='gzip', lines=True, nrows=100)\n",
    "df_yt_metadata.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 user-comment matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh /dlabdata1/youtube_large/youtube_comments.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-comment matrices\n",
    "df_yt_comments = pd.read_csv(DATA_FOLDER+'youtube_comments.tsv.gz', sep=\"\\t\", compression='gzip', nrows=100)\n",
    "df_yt_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5 raw comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh /dlabdata1/youtube_large/youtube_comments.ndjson.zst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_jsonify(line): \n",
    "    \"\"\"\n",
    "\n",
    "    :param line: string to parse and jsonify\n",
    "    :return: \n",
    "    \"\"\"    \n",
    "    \n",
    "    # add square brackets around line\n",
    "    line = \"[\" + line + \"]\"\n",
    "\n",
    "    # remove quotes before and after square brackets   \n",
    "    line = line.replace(\"\\\"[{\", \"[{\")\n",
    "    line = line.replace(\"}]\\\"\", \"}]\")    \n",
    "    \n",
    "    # replace double double-quotes with single double-quotes\n",
    "    line = line.replace(\"{\\\"\\\"\", \"{\\\"\")\n",
    "    line = line.replace(\"\\\"\\\"}\", \"\\\"}\")\n",
    "    line = line.replace(\"\\\"\\\":\\\"\\\"\", \"\\\":\\\"\")\n",
    "    line = line.replace(\":\\\"\\\"\", \":\\\"\")\n",
    "    line = line.replace(\"\\\"\\\":\", \"\\\":\")\n",
    "    \n",
    "    # line = line.replace(\"\\\"\\\":\", \"\\\":\")\n",
    "    line = line.replace(\"\\\"\\\",\\\"\\\"\", \"\\\",\\\"\")\n",
    "    line = line.replace(\"\\\"\\\",\\\"\\\"\", \"\\\",\\\"\")\n",
    "    line = line.replace(\"\\\\\\\"\\\"\", \"\\\\\\\"\")\n",
    "    line = line.replace(\"\\\\\\\",[\", \"\\\\\\\\ \\\",[\")\n",
    "    \n",
    "    line = re.sub(r',\\\"\\\"(?!\\,)', ',\\\"', line)\n",
    "\n",
    "    line = line.replace(\"true,\\\"\\\"\", \"true,\\\"\")\n",
    "    line = line.replace(\"false,\\\"\\\"\", \"false,\\\"\")\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        import codecs\n",
    "        self.fh = open(file,'rb')\n",
    "        print(f\"reading {file} in chunks ...\")\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstandard.ZstdDecompressor(max_window_size=2147483648)\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        nb_chunk = 0\n",
    "        while True:\n",
    "            nb_chunk = nb_chunk + 1\n",
    "            if nb_chunk % 5000 == 0:\n",
    "                print(\"number of chunks read: \", nb_chunk)\n",
    "                \n",
    "            chunk = self.reader.read(self.chunk_size).decode(\"utf-8\", \"replace\")\n",
    "\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            # print(\"lines per chunk: \", len(lines))\n",
    "            # print(lines)\n",
    "            \n",
    "            for line in lines[:-1]:\n",
    "                # print(line)\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_LINES = 350000\n",
    "lines_json = []\n",
    "inp_file = DATA_FOLDER+\"youtube_comments.ndjson.zst\"\n",
    "reader = Zreader(inp_file, chunk_size=4092)\n",
    "\n",
    "for i, line in enumerate(reader.readlines()):\n",
    "    if i > NB_OF_LINES:\n",
    "        # print(line)\n",
    "        break\n",
    "    line_json = json.loads(line_jsonify(line))\n",
    "    lines_json.append(line_json)\n",
    "\n",
    "print(\"==> number of lines read:\", len(lines_json))\n",
    "\n",
    "df_yt_comments_raw = pd.DataFrame(data=lines_json[1:], columns=lines_json[0])\n",
    "df_yt_comments_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Graphtreon dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 List with all creator names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh /dlabdata1/youtube_large/creators.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with all creator names.\n",
    "df_gt_creators = pd.read_csv(DATA_FOLDER+'creators.csv')\n",
    "df_gt_creators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 All graphtreon time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh /dlabdata1/youtube_large/final_processed_file.jsonl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_processed_file.jsonl.gz all graphteon time-series.\n",
    "df_gt_timeseries = pd.read_json(DATA_FOLDER+'final_processed_file.jsonl.gz', compression='gzip', lines=True, nrows=100)\n",
    "df_gt_timeseries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Raw html of the pages in graphteon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /dlabdata1/youtube_large/pages.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages.zip raw html of the pages in graphteon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Merge channels data with YouTube timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_yt_timeseries.head(1))\n",
    "display(df_yt_channels.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt_timeseries_merged = df_yt_timeseries.merge(df_yt_channels, how='inner', on='channel')\n",
    "\n",
    "# remove duplicate columns\n",
    "# df_yt_timeseries_merged.drop('category_cc', axis='columns', inplace=True)\n",
    "\n",
    "df_yt_timeseries_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Merge YouTube timeseries and Graphtreon timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Channel metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 YouTube time-series EDA\n",
    "This data is from the YouNiverse dataset, a large collection of channel and video metadata from English-language YouTube. YouNiverse comprises metadata from over 136k channels and 72.9M **videos published between May 2005 and October 2019**, as well as channel-level time-series data with weekly subscriber and view counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"Total number of datapoints in YouTube timeseries file: {len(df_yt_timeseries_merged):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Columns of the merged YouTube timeseries dataframe\")\n",
    "# # df_yt_timeseries_merged.columns\n",
    "# [col for col in df_yt_timeseries_merged.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt_timeseries_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Videos per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_channel = df_yt_timeseries_merged.groupby('channel')[['videos_cc', 'subscribers_cc']].agg(['max'])\n",
    "\n",
    "# set the columns to the top level of the multi-index\n",
    "data_per_channel.columns = data_per_channel.columns.get_level_values(0)\n",
    "data_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_channel[['videos_cc']].sort_values('videos_cc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Videos and subscribers per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data_per_channel.columns\n",
    "\n",
    "# nice plot!\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "for i,(col,ax) in enumerate(zip(numeric_cols, axs.flatten())):\n",
    "    sns.histplot(data=data_per_channel[col], ax=ax, bins=50, kde=False, color=f'C{i}')\n",
    "\n",
    "    ax.set(title=f'Distribution of {col}')\n",
    "    ax.set(yscale=\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# nice table!\n",
    "data_per_channel.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the histogram of the data\n",
    "# plt.hist(data_per_channel['videos_cc'], 100, facecolor='g', log=True, density=True, alpha=0.75)\n",
    "\n",
    "# # plt.xscale('log',base=10) \n",
    "\n",
    "# plt.xlabel('# videos')\n",
    "# plt.ylabel('Density')\n",
    "# plt.title('Histogram of videos per channel')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MATPLOTLIB EQUIVALENT\n",
    "# fig, ax = plt.subplots(1,2, figsize=(10,5),  sharey=False, sharex=False)\n",
    "\n",
    "# # ax[0].ticklabel_format(axis='x', style='scientific', scilimits=(-9,9))\n",
    "# ax[0].ticklabel_format(axis='x', style='plain')\n",
    "# ax[0].hist(data_per_channel['videos_cc'], bins = 60, color='blue', log=True, alpha=0.3)\n",
    "# ax[0].set_title('Videos per channel')\n",
    "# ax[0].set_xlabel('# videos')    \n",
    "# ax[0].set_ylabel('count')    \n",
    "# # ax[0].set_xscale('log', base=10) \n",
    "\n",
    "\n",
    "# ax[1].ticklabel_format(axis='x', style='scientific', scilimits=(-6,6))\n",
    "# ax[1].hist(data_per_channel['subscribers_cc'], bins = 60, color='blue', log=True, alpha=0.3)\n",
    "# ax[1].set_title('Subscribers per channel')\n",
    "# ax[1].set_xlabel('# subscribers')    \n",
    "# ax[1].set_ylabel('count')    \n",
    "# # ax[1].set_xscale('log', base=10) \n",
    "\n",
    "# # fig.suptitle('Distribution of the data', fontweight=\"bold\")\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Distribution of datetime points per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all channels timeseries start and end at the same time, therefore we have a different amount of datapoints for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_data = df_yt_timeseries_merged.groupby('channel')['datetime'].agg(['min', 'max'])\n",
    "datetime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Distribution per categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt_timeseries_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_cat_chan = df_yt_timeseries_merged.groupby(['category', 'channel'])['videos_cc', 'subscribers_cc'].agg(['max'])\n",
    "\n",
    "# set the columns to the top level of the multi-index\n",
    "data_per_cat_chan.columns = data_per_cat_chan.columns.get_level_values(0)\n",
    "data_per_cat_chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_cat_chan.reset_index(inplace=True)\n",
    "data_per_cat_chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nb of channels per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_per_cat = data_per_cat_chan.groupby('category')[['channel']].count().sort_values('channel', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_per_cat.plot(kind='bar')\n",
    "plt.title(\"Number of channels per category\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Number of channels\")\n",
    "plt.show()\n",
    "chan_per_cat['channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_per_cat = data_per_cat_chan.groupby('category')['videos_cc','subscribers_cc'].agg(['min', 'max', 'count', 'sum'])\n",
    "data_per_cat = data_per_cat_chan.groupby('category')[['videos_cc','subscribers_cc']].agg(['sum'])\n",
    "data_per_cat.columns = data_per_cat.columns.get_level_values(0)\n",
    "data_per_cat = data_per_cat.add_suffix('_sum')\n",
    "data_per_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique categories: \", len(data_per_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Videos per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_cat['videos_cc_sum'].sort_values(ascending=False).plot(kind='bar')\n",
    "plt.title(\"Number of videos per category\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Number of videos\")\n",
    "plt.show()\n",
    "\n",
    "data_per_cat['videos_cc_sum'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subscribers per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_cat['subscribers_cc_sum'].sort_values(ascending=False).plot(kind='bar')\n",
    "plt.title(\"Number of subscribers per category\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Number of videos\")\n",
    "plt.show()\n",
    "\n",
    "data_per_cat['subscribers_cc_sum'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Distribution of videos per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt_timeseries_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_id_dist = df_yt_timeseries_merged[['channel', 'name_cc']].value_counts()\n",
    "chan_id_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_id_dist = df_yt_timeseries_merged['channel'].value_counts()\n",
    "print(\"Number of unique channels id are: \", len(chan_id_dist))\n",
    "print(chan_id_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_id_dist.hist()\n",
    "plt.title(\"Histogram: number of data points per channel\")\n",
    "plt.xlabel(\"Number of data points\")\n",
    "plt.ylabel(\"Number of channels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some channel names have different ids, ex:\n",
    "print(\"Warning: A same channel name can have different ids, for example, the following channel ids all have the same name 'Kai':\")\n",
    "kai_chan_id = df_yt_timeseries_merged[df_yt_timeseries_merged['name_cc'] == 'Kai']['channel'].value_counts()\n",
    "\n",
    "for id in kai_chan_id.index:\n",
    "    print('https://www.youtube.com/channel/' + id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dist.plot(kind='bar')\n",
    "plt.title(\"Distribution of YouTube channels per categories\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Number of videos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Number of views per category per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yt_timeseries_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
